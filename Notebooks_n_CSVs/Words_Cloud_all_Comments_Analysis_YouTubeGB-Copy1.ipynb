{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa98a60-e935-4d31-8e06-0c18e2ec94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28353b33-ae9d-4f40-a1f6-1f4f77729cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('words')\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#plt.style.use('ggplot')\n",
    "import nltk\n",
    "import pickle\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809f0c62-7f80-4b5e-b20e-6ac75ddee672",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>negative_comments</th>\n",
       "      <th>neutral_comments</th>\n",
       "      <th>positive_comments</th>\n",
       "      <th>compound_comments</th>\n",
       "      <th>Analysis_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jt2OHQh0HoQ</td>\n",
       "      <td>It's more accurate to call it the M+ (1000) be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jt2OHQh0HoQ</td>\n",
       "      <td>To be there with a samsung phone\\n______</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jt2OHQh0HoQ</td>\n",
       "      <td>Thank gosh, a place I can watch it without hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jt2OHQh0HoQ</td>\n",
       "      <td>What happened to the home button on the iPhone...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jt2OHQh0HoQ</td>\n",
       "      <td>Power is the disease._ Care is the cure._ Keep...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718448</th>\n",
       "      <td>XQFeShp6UIY</td>\n",
       "      <td>Exploit used = Not World__ First. Simple.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718449</th>\n",
       "      <td>XQFeShp6UIY</td>\n",
       "      <td>Some exotics in Destiny have hidden perks. The...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718450</th>\n",
       "      <td>XQFeShp6UIY</td>\n",
       "      <td>Why is there a race if it's literally the same...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718451</th>\n",
       "      <td>XQFeShp6UIY</td>\n",
       "      <td>Who the fuck cares about some stupid heavy gli...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718452</th>\n",
       "      <td>XQFeShp6UIY</td>\n",
       "      <td>So using mechanics built into the raid is chea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407736 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           video_id                                       comment_text  likes  \\\n",
       "0       jt2OHQh0HoQ  It's more accurate to call it the M+ (1000) be...      0   \n",
       "1       jt2OHQh0HoQ           To be there with a samsung phone\\n______      1   \n",
       "2       jt2OHQh0HoQ  Thank gosh, a place I can watch it without hav...      0   \n",
       "3       jt2OHQh0HoQ  What happened to the home button on the iPhone...      0   \n",
       "4       jt2OHQh0HoQ  Power is the disease._ Care is the cure._ Keep...      0   \n",
       "...             ...                                                ...    ...   \n",
       "718448  XQFeShp6UIY          Exploit used = Not World__ First. Simple.      2   \n",
       "718449  XQFeShp6UIY  Some exotics in Destiny have hidden perks. The...      3   \n",
       "718450  XQFeShp6UIY  Why is there a race if it's literally the same...      1   \n",
       "718451  XQFeShp6UIY  Who the fuck cares about some stupid heavy gli...      0   \n",
       "718452  XQFeShp6UIY  So using mechanics built into the raid is chea...      0   \n",
       "\n",
       "        replies  negative_comments  neutral_comments  positive_comments  \\\n",
       "0             0              0.310             0.690              0.000   \n",
       "1             0              0.310             0.690              0.000   \n",
       "2             0              0.310             0.690              0.000   \n",
       "3             0              0.310             0.690              0.000   \n",
       "4             0              0.310             0.690              0.000   \n",
       "...         ...                ...               ...                ...   \n",
       "718448        2              0.171             0.667              0.162   \n",
       "718449        4              0.171             0.667              0.162   \n",
       "718450        3              0.171             0.667              0.162   \n",
       "718451        2              0.171             0.667              0.162   \n",
       "718452        1              0.171             0.667              0.162   \n",
       "\n",
       "        compound_comments Analysis_comments  \n",
       "0                 -0.5574          Negative  \n",
       "1                 -0.5574          Negative  \n",
       "2                 -0.5574          Negative  \n",
       "3                 -0.5574          Negative  \n",
       "4                 -0.5574          Negative  \n",
       "...                   ...               ...  \n",
       "718448            -0.0516          Negative  \n",
       "718449            -0.0516          Negative  \n",
       "718450            -0.0516          Negative  \n",
       "718451            -0.0516          Negative  \n",
       "718452            -0.0516          Negative  \n",
       "\n",
       "[407736 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.sort_values(by = 'likes',ascending =False).head(10)\n",
    "word_cloud= pd.read_csv('Centimental_Analysis_YouTubeGB_results.csv')\n",
    "\n",
    "# df_like_replies = df_like_dislikes[['likes', 'replies', 'Analysis_comments']]\n",
    "# df_like_replies#.reset_index(inplace=True)\n",
    "# df_like_replies= df_like_dislikes.rename(columns = {'index':'video_id'})\n",
    "word_cloud.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f09a994-7668-4b4c-8d08-72d888367624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id\n",
       "#NAME?         10318\n",
       "LunHybOKIjU     1200\n",
       "Q0CbN8sfihY     1199\n",
       "t3AVtQkEHaE     1100\n",
       "r9-DM9uBtVI     1050\n",
       "               ...  \n",
       "9lx41ak9GWk        4\n",
       "35zynOrkvMk        3\n",
       "srr_7fM-hL4        2\n",
       "utPFb_tNARo        2\n",
       "jNb0vRORLAw        2\n",
       "Name: comment_text, Length: 1669, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cloud.groupby('video_id')['comment_text'].count().sort_values(ascending=False) # finding the top 1 video id has the most comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ffdaeb-5b9f-4628-9194-9891b726ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud=word_cloud[['video_id','comment_text','likes','replies','Analysis_comments']]\n",
    "word_cloud.drop_duplicates(inplace=True)\n",
    "word_cloud.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fd4eaa3-8f31-4316-bec9-13d99923ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.merge(df_like_dislikes,on='video_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1acc49e8-b059-4dd3-b21d-fc9ad790698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(407736, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cloud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac652d0-6f95-4192-8b1f-53a764a7c83d",
   "metadata": {},
   "source": [
    "# Comments annalysis on Top1 videoId "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d878d9-47ff-4e87-b8a6-9a1f01e7d540",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "## Step 1. VADER Setiment Scoring, we will use SentimentIntensityAnalyzer\n",
    "\n",
    "    this uses a \"bag of words\"approach\n",
    "    1.stop words are removed \n",
    "    2. each word is scored and combined to a total score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449f84a-fb45-4b37-b43d-2e1f2d26dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "731c9304-4d18-43b1-a135-eb114a499bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"0         It's more accurate to call it the M+ (1000) be...\\n1                  To be there with a samsung phone\\\\n______\\n2         Thank gosh, a place I can watch it without hav...\\n3         What happened to the home button on the iPhone...\\n4         Power is the disease._ Care is the cure._ Keep...\\n                                ...                        \\n718448            Exploit used = Not World__ First. Simple.\\n718449    Some exotics in Destiny have hidden perks. The...\\n718450    Why is there a race if it's literally the same...\\n718451    Who the fuck cares about some stupid heavy gli...\\n718452    So using mechanics built into the raid is chea...\\nName: comment_text, Length: 407736, dtype: object\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(word_cloud['comment_text']).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214c8be-48c7-4a11-a142-55391b042c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f35830-0220-4114-81a4-34ad81c696b6",
   "metadata": {},
   "source": [
    "# run the polarity score to the entire df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "006c4a9d-9d63-4eb9-adbd-f474da98345c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>Analysis_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's more accurate to call it the M+ (1000) be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To be there with a samsung phone\\n______</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank gosh, a place I can watch it without hav...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What happened to the home button on the iPhone...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Power is the disease._ Care is the cure._ Keep...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718448</th>\n",
       "      <td>Exploit used = Not World__ First. Simple.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718449</th>\n",
       "      <td>Some exotics in Destiny have hidden perks. The...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718450</th>\n",
       "      <td>Why is there a race if it's literally the same...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718451</th>\n",
       "      <td>Who the fuck cares about some stupid heavy gli...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718452</th>\n",
       "      <td>So using mechanics built into the raid is chea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407736 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  likes  replies  \\\n",
       "0       It's more accurate to call it the M+ (1000) be...      0        0   \n",
       "1                To be there with a samsung phone\\n______      1        0   \n",
       "2       Thank gosh, a place I can watch it without hav...      0        0   \n",
       "3       What happened to the home button on the iPhone...      0        0   \n",
       "4       Power is the disease._ Care is the cure._ Keep...      0        0   \n",
       "...                                                   ...    ...      ...   \n",
       "718448          Exploit used = Not World__ First. Simple.      2        2   \n",
       "718449  Some exotics in Destiny have hidden perks. The...      3        4   \n",
       "718450  Why is there a race if it's literally the same...      1        3   \n",
       "718451  Who the fuck cares about some stupid heavy gli...      0        2   \n",
       "718452  So using mechanics built into the raid is chea...      0        1   \n",
       "\n",
       "       Analysis_comments  \n",
       "0               Negative  \n",
       "1               Negative  \n",
       "2               Negative  \n",
       "3               Negative  \n",
       "4               Negative  \n",
       "...                  ...  \n",
       "718448          Negative  \n",
       "718449          Negative  \n",
       "718450          Negative  \n",
       "718451          Negative  \n",
       "718452          Negative  \n",
       "\n",
       "[407736 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topid_name=df.query('video_id == \"#NAME?\"')\n",
    "word_cloud=word_cloud[['comment_text','likes','replies','Analysis_comments']] # finding the top 1 video id has the most comments\n",
    "word_cloud # now we have topid thathas most commnets and we can anaysis how his/her audiance feel about his videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb311cc-b78b-490c-b843-3a0a829188cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d0e48db-df2a-40ec-96f1-2f1b199a9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1652098-8213-47f2-a697-14343ea8654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud.loc[:,'comment_text'] = word_cloud.loc[:,'comment_text'].str.replace('\\!','',regex=True)\n",
    "word_cloud.loc[:,'comment_text'] = word_cloud.loc[:,'comment_text'].str.replace('\\-','',regex=True)\n",
    "word_cloud.loc[:,'comment_text'] = word_cloud.loc[:,'comment_text'].str.replace('\\|','',regex=True)\n",
    "word_cloud.loc[:,'comment_text'] = word_cloud.loc[:,'comment_text'].str.replace('https?:\\/\\/\\S+','',regex=True)\n",
    "word_cloud.loc[:,'comment_text'] = word_cloud.loc[:,'comment_text'].str.replace('\\\\','',regex=True)\n",
    "word_cloud.loc[:,'comment_text'] = word_cloud.loc[:,'comment_text'].str.replace('_____','',regex=True)\n",
    "word_cloud.loc[:,'comment_text'] = word_cloud.loc[:,'comment_text'].str.replace('__','',regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83f5d8f1-72ed-426f-a790-0415bb7fbb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 407736 entries, 0 to 718452\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   comment_text       407736 non-null  object\n",
      " 1   likes              407736 non-null  int64 \n",
      " 2   replies            407736 non-null  int64 \n",
      " 3   Analysis_comments  407736 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 15.6+ MB\n"
     ]
    }
   ],
   "source": [
    "word_cloud.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffbce6ea-b2f2-4fca-b27e-7ad7ee347012",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = word_cloud['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f0c3660-098f-47c8-8029-e824b891a818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_str\u001b[49m()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_str'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09ce9b37-450f-4e4b-bf85-72c13345afca",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:632\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:613\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_from_frequencies(words)\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:575\u001b[0m, in \u001b[0;36mWordCloud.process_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    572\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_word_length \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m regexp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pattern\n\u001b[0;32m--> 575\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# remove 's\u001b[39;00m\n\u001b[1;32m    577\u001b[0m words \u001b[38;5;241m=\u001b[39m [word[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m word\n\u001b[1;32m    578\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/re.py:241\u001b[0m, in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "wordcloud = WordCloud().generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52082fa8-eb02-4fb6-b8a4-1da1796b8970",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(wordcloud, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:632\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:613\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_from_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_from_frequencies(words)\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:575\u001b[0m, in \u001b[0;36mWordCloud.process_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    572\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_word_length \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m regexp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregexp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pattern\n\u001b[0;32m--> 575\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# remove 's\u001b[39;00m\n\u001b[1;32m    577\u001b[0m words \u001b[38;5;241m=\u001b[39m [word[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m word\n\u001b[1;32m    578\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/re.py:241\u001b[0m, in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea01919-e603-496c-b807-75cff4d8c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topid.to_csv('TopID_Comments_Analysis_YouTubeGB.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17548918-3c80-41ea-b387-daacc316d4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a75266-d0be-4562-a032-1ce511825cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc88c99-0f5b-4cd3-b4ed-8f43e8f18f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b0b53-a299-40bc-8f66-564531c7eb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9ac16-98d8-4a13-9ae5-ce5cbb927f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ae512-6d3f-4e84-acd0-1164fab6262a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d02026-3f53-4cb2-9a28-e20756b73fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c329f31-f2f9-4268-b3c2-c77de27b3653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b4f810-8fb5-4ab5-8947-cdfa58bd3190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
